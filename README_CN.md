<p align="right">
  <a href="README_CN.md">简体中文</a> | <a href="README.md">English</a>
</p>

# RWSearch
**RWSearch： 一个面向智能体的高阶逻辑与真实世界搜索评估基准。**

本评测集是一套严密的评测基准，旨在深度评估大模型及其Agent在中文语境下的认知深度、多维检索、长程推理及精确计算执行能力。

## 💡 评测集核心特征
🎯 RWSearch由专家撰写的200道真实、复杂问题组成，每道题目提供唯一客观答案。

🎯 RWSearch以“锚定真实”为核心设计理念，将 Agent置于复杂多变的真实互联网生态中。题目设计兼顾正向检索与反向推理，引入大量数字澄清、统计演算与动态比较环节，重点强化对高时效信息与超长逻辑链条的考核。

### 真实世界动态演进的真实测绘
**核心描述：** 本评测集高度关注全球化视野下的高时效、真实细分场景问题。要求 Agent 像人类专家一样捕捉流动信息中的瞬时态势。
- **全球化与本土化的交织：** 任务既涵盖国际话题（如 Billboard 榜单、NBA 赛事、诺贝尔奖等），又深入中国本土事务细节（如客运量统计、畜牧品种、就业供需等）。
- **多维垂类的信息整合：** 单一 Query 可以横跨工程、体育、教育等多个垂直领域，关联维度涵盖人际关系、商业隶属、时空演算等，考验模型的实体关联与信息整合能力。
- **高时效与反记忆设计：** 内容覆盖 2024 年末至 2025 年的动态事实，限制模型依赖“预训练记忆”，强制其进行实时浏览与信息核验。

**数据统计：**
- **领域：** 本评测集涵盖了影音娱乐、公共事务、生产消费、文学艺术、经济商业、科学技术、体育运动、时政法律八大领域，全面覆盖互联网深度调研的真实场景。每道题目可能涉及多个垂类，此处统计以终极问题所属垂类为准。

| 领域     | 题目数量 | 占比 |
|----------|----------|------|
| 影音娱乐 | 54       | 27%  |
| 公共事务 | 34       | 17%  |
| 生产消费 | 28       | 14%  |
| 文学艺术 | 27       | 14%  |
| 经济商业 | 17       | 9%   |
| 科学技术 | 15       | 8%   |
| 体育运动 | 14       | 7%   |
| 时政法律 | 11       | 6%   |
| 总计     | 200      | 100% |

- **新鲜度：** 新鲜度指标定义为题目涉及信息中最新信息所处年份，用于衡量模型对最新信息的获取能力。本评测集中60%的题目涉及2025年信息，与真实世界紧密连接。

| 新鲜度       | 题目数量 | 占比 |
|--------------|----------|------|
| 2025年       | 119      | 60%  |
| 2024年       | 48       | 24%  |
| 2023年及以前 | 33       | 17%  |

### 基于“数字澄清、计算与比较”的实体决策

**核心特征描述：** 部分题目中，Agent必须通过筛选、排序、计算等手段在候选集中“筛选”出目标，才能进行下一步搜索或问题回答。
- **多维比较确定唯一性：** 问题中常包含“排名第x”、“差值最值”、“同比增加”等量化指令，并组合形成复杂约束条件。
- **高精度数学执行：** 要求将网页数据转化为结构化数值，并完成诸如“自然日差值”、“比例四舍五入”等精确运算操作。

**示例**
- **原始题目：** 截至2025年6月，获得最多的大满贯单打冠军的运动员在其职业生涯中与获得大满贯单打冠军数排名第二的男子运动员交手过多少次？（仅统计官方正规赛事）
- **执行难度：** Agent 必须检索网球运动员的大满贯冠军数并进行排名，定位“第一名”和“第二名”，进而检索二人的交手记录。任何数据遗漏或计算错误均会导致实体偏离及答案错误。


## ⚖️ 相比同类评测集的优势剖析

🎯 RW Search贴近真实场景下的用户问题，希望将评测重点由“解析复杂Query，多步推理能力”转向“真实噪声场景下的答案搜索能力”，后者更能体现当下用户的真实需求。

🎯 RW Search通过精选“时间锁定”的事实，确保评测结果具有高度可重复性与跨模型对比的科学性。解决同类评测集随时间演变导致答案失效的问题。

### 语义表述的极高清晰度与指令严谨性
**同类评测集痛点：** 市面上部分数据集存在约束表述主观模糊，主体/时间指代不清等问题，导致模型表现受限于理解偏差。

**本评测集特征：** 提供了极高清晰度的约束指令，输出严格限制为“数字”、“时间日期”或“特定实体”等格式明确的简短答案。
- 对数字/时间日期类答案约束单位、小数格式、正负号、时间格式；对于实体类答案约束语言、全称/缩写、地理区划粒度等。
- 对于易混淆概念进行唯一性界定，如“对海外名称同时给出原名和中译名”、“对奖项明确届数而非仅年份；或进行清晰的补充说明，如”统计摩天大楼时明确不含未建成建筑，高度以总高为准”、“统计动漫主题曲时说明包含OP、ED和MT”。

### 真实搜索生态中的“信息噪音”对抗
**同类评测集痛点：** 许多数据集的信源相对“干净”，答案通常来自百科词条，脱离真实调研场景，无法考查 Agent 在面对相似术语、层级数据或过时信息时的辨析力。

**本评测集特征：** 大量关注隐藏在专业深度数据、政府公报、企业年报及行业报告中的问题。题目设计引入“近义干扰”和“层级陷阱”，要求 Agent 具备极强的数据颗粒度感知能力，能够从高度相似的专业术语中甄别出唯一准确的信息源。

- **专业术语辨析：** 引入近义干扰，要求 Agent 区分细微统计口径（如“公路”vs“水路”客运量，“常住”vs“年末”人口），Agent 必须识别术语背后的统计口径差异，而非盲目抓取。

- **层级与深度检索：** 要求深入官方公报或行业报告，从复杂统计图表中提取数据，跨越年份清洗并聚合数据，避开“层级陷阱”（如行政区划级别混淆）。

### 答案的恒久稳定性与客观真值的唯一 
**同类评测集痛点：** 许多相关数据集存在“移动靶”问题，同一题目随现实变化可能会导致答案改变，甚至从唯一解变成多解或无解。

**本评测集特征：** 本评测集虽然关注真实动态的世界，但题目设计遵循“动态过程、静态结果”原则，保证答案唯一不变。
- **锚定具有物理或逻辑确定性的事实，** 如“已发布的统计公报数值”、“特定时点的展览信息“或“固定年份的排名”。
- **关注最新信息的同时设置截止时间，** 要求Agent 主动过滤过时数据或无效猜测，锁定官方最新发布并匹配截止时间要求，保障答案不变。

## 📚 数据样例

<table>
  <tr>
    <th>领域</th>
    <th>题目</th>
    <th>标准答案</th>
  </tr>
  <tr>
    <td nowrap>体育运动</td>
    <td>2023-2024 赛季 NBA 常规赛中，尼古拉・约基奇在最后10场比赛中的三分球命中率（百分比，四舍五入保留一位小数）是多少？</td>
    <td nowrap>39.4%</td>
  </tr>
  <tr>
    <td nowrap>公共事务</td>
    <td>2020-2024年5年间，中国民航机场旅客吞吐量累积排名第五高的机场，在这5年的累计旅客吞吐量是多少（单位：亿人次，四舍五入保留2位小数）</td>
    <td nowrap>1.86亿人次</td>
  </tr>
  <tr>
    <td nowrap>生产消费</td>
    <td>2024年3月到12月期间，社会消费品零售总额同比增长最快的月份，比增长最慢的月份，多增长了几个百分点？</td>
    <td nowrap>2.8个</td>
  </tr>
  <tr>
    <td nowrap>经济商业</td>
    <td>2020年至2024年期间，小米集团总收入最低那年的年度经营利润是多少（四舍五入到个位，人民币，单位：亿元）？</td>
    <td nowrap>240亿元</td>
  </tr>
  <tr>
    <td nowrap>影音娱乐</td>
    <td>五月天"5525 回到那一天"主题演唱会的第66场是在哪个场馆举办的？</td>
    <td nowrap>新加坡国家体育场</td>
  </tr>
</table>


## 🏆 排行榜
### 模型榜单（w/o 上下文管理）
<table>
  <tr>
    <th>类型</th>
    <th>模型</th>
    <th>分数</th>
  </tr>
  <tr>
    <td rowspan="3">闭源模型</td>
    <td>gpt-5.2-thinking (xhigh)</td>
    <td><b>82.0</b></td>
  </tr>
  <tr>
    <td>gemini-3-pro-preview</td>
    <td>74.5</td>
  </tr>
  <tr>
    <td>claude-opus-4.5</td>
    <td>75.5</td>
  </tr>
  <tr>
    <td rowspan="5">开源模型</td>
    <td>longcat-flash-thinking-2601</td>
    <td><b>79.5</b></td>
  </tr>
  <tr>
    <td>deepseek-v3.2-reasoner</td>
    <td>74.0</td>
  </tr>
  <tr>
    <td>glm-4.7-thinking</td>
    <td>69.0</td>
  </tr>
  <tr>
    <td>kimi-k2-thinking</td>
    <td>63.0</td>
  </tr>
  <tr>
    <td>qwen3-235b-a22b-thinking-2507</td>
    <td>20.5</td>
  </tr>
  <tr>
    <td colspan="3" align="center"><i>更多模型指标敬请期待...</i></td>
  </tr>
</table>

> 指标**加粗**代表同类型模型中的最优表现。

### Search Agent榜单（w/ 上下文管理）
敬请期待...

## 📖 引用

如果您使用了本项目的代码或资源，请按以下格式引用：

```bibtex
@misc{rwsearch2026,
  author       = {Zhu, Mingyang and Liu, Wei and others},
  title        = {RW-Search: A High-Order Logic and Real-World Search Evaluation Benchmark for Agents},
  year         = {2026},
  url          = {https://github.com/AGI-Eval-Official/RW-Search}
}
```

## ☁️ 联系我们

如果您有任何问题，请通过以下方式联系我们：

作者邮箱：zhumingyang09@meituan.com, liuwei304@meituan.com